{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "def train_and_save(pipelines, dataset_name, x, y):\n",
    "    try:\n",
    "        results = load_json(\n",
    "            f'../artefacts/6/results_{dataset_name}.json')\n",
    "    except:\n",
    "        results = {}\n",
    "\n",
    "    for model_name, params, pipeline in pipelines:\n",
    "        start = time.time()\n",
    "        print(f\"Training {model_name}\", end=' -> ')\n",
    "        pipeline.set_params(**params.get('best_parameters'))\n",
    "        pipeline.fit(x, y)\n",
    "        print(f\"Saving {model_name}\", end=' -> ')\n",
    "        score = pipeline.score(x.iloc[:10000], y.iloc[:10000])\n",
    "        print(f\"Score: {score}\")\n",
    "        joblib.dump(\n",
    "            pipeline, f'../artefacts/6/models_{dataset_name}_{model_name}.joblib')\n",
    "        end = time.time()\n",
    "\n",
    "        try:\n",
    "            results[model_name]['train'] = {\n",
    "                'time': end - start,\n",
    "                'score': score\n",
    "            }\n",
    "        except:\n",
    "            results[model_name] = {\n",
    "                'train': {\n",
    "                    'time': end - start,\n",
    "                    'score': score\n",
    "                }\n",
    "            }\n",
    "\n",
    "        with open(f'../artefacts/6/results_{dataset_name}.json', 'w+') as f:\n",
    "            json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ada_boost -> Saving ada_boost -> Score: 0.9904\n",
      "Training decision_tree -> Saving decision_tree -> Score: 0.9986\n",
      "Training knn -> Saving knn -> Score: 0.9999\n",
      "Training logistic_regression -> Saving logistic_regression -> Score: 0.96\n",
      "Training mlp -> Saving mlp -> Score: 0.9816\n",
      "Training random_forest -> Saving random_forest -> Score: 0.997\n",
      "Training svm -> Saving svm -> Score: 0.9971\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# kdd\n",
    "\n",
    "verbose = False\n",
    "\n",
    "kdd_pipelines = [\n",
    "    (\n",
    "        \"ada_boost\",\n",
    "        load_json('../artefacts/6/params_kdd_ada_boost.json'),\n",
    "        Pipeline(\n",
    "            [\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', OneVsRestClassifier(\n",
    "                    AdaBoostClassifier(), verbose=verbose, n_jobs=-1))\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"decision_tree\",\n",
    "        load_json('../artefacts/6/params_kdd_decision_tree.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', DecisionTreeClassifier())\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"knn\",\n",
    "        load_json('../artefacts/6/params_kdd_knn.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', KNeighborsClassifier(n_jobs=-1))\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"logistic_regression\",\n",
    "        load_json('../artefacts/6/params_kdd_logistic_regression.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', OneVsRestClassifier(\n",
    "                    LogisticRegression(n_jobs=-1, verbose=verbose), verbose=verbose, n_jobs=-1))\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"mlp\",\n",
    "        load_json('../artefacts/6/params_kdd_mlp.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', MLPClassifier(verbose=verbose))\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"random_forest\",\n",
    "        load_json('../artefacts/6/params_kdd_random_forest.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', RandomForestClassifier(verbose=verbose, n_jobs=-1))\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"svm\",\n",
    "        load_json('../artefacts/6/params_kdd_svm.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', OneVsRestClassifier(\n",
    "                    SVC(verbose=verbose), verbose=verbose, n_jobs=-1))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "df_kdd = pd.read_csv('../artefacts/5/kdd_train.csv', index_col=0)\n",
    "\n",
    "kdd_x = df_kdd.iloc[:, :-3]\n",
    "kdd_y = df_kdd.iloc[:, -3:]\n",
    "\n",
    "train_and_save(kdd_pipelines, 'kdd', kdd_x, kdd_y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training IoT Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ada_boost -> Saving ada_boost -> Score: 0.7984\n",
      "Training decision_tree -> Saving decision_tree -> Score: 0.8496\n",
      "Training knn -> Saving knn -> Score: 0.9317\n",
      "Training logistic_regression -> Saving logistic_regression -> Score: 0.7114\n",
      "Training mlp -> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donkushanathalage/Desktop/sit719/env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving mlp -> Score: 0.8088\n",
      "Training random_forest -> Saving random_forest -> Score: 0.8737\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "\n",
    "iot_pipelines = [\n",
    "    (\n",
    "        \"ada_boost\",\n",
    "        load_json('../artefacts/6/params_iot_ada_boost.json'),\n",
    "        Pipeline(\n",
    "            [\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', OneVsRestClassifier(\n",
    "                    AdaBoostClassifier(), verbose=verbose, n_jobs=-1))\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"decision_tree\",\n",
    "        load_json('../artefacts/6/params_iot_decision_tree.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', DecisionTreeClassifier())\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"knn\",\n",
    "        load_json('../artefacts/6/params_iot_knn.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', KNeighborsClassifier(n_jobs=-1))\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"logistic_regression\",\n",
    "        load_json('../artefacts/6/params_iot_logistic_regression.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', OneVsRestClassifier(\n",
    "                    LogisticRegression(n_jobs=-1, verbose=verbose), verbose=verbose, n_jobs=-1))\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"mlp\",\n",
    "        load_json('../artefacts/6/params_iot_mlp.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', MLPClassifier(verbose=verbose))\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        \"random_forest\",\n",
    "        load_json('../artefacts/6/params_iot_random_forest.json'),\n",
    "        Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', RandomForestClassifier(verbose=verbose, n_jobs=-1))\n",
    "        ])\n",
    "    ),\n",
    "\n",
    "    # (\n",
    "    #     \"svm\",\n",
    "    #     load_json('../artefacts/6/params_iot_svm.json'),\n",
    "    #     Pipeline([\n",
    "    #             ('scaler', StandardScaler()),\n",
    "    #             ('clf', OneVsRestClassifier(\n",
    "    #                 SVC(verbose=verbose), verbose=verbose, n_jobs=-1))\n",
    "    #     ])\n",
    "    # )\n",
    "\n",
    "]\n",
    "\n",
    "df_iot = pd.read_csv('../artefacts/5/iot_train.csv')\n",
    "\n",
    "iot_x = df_iot.iloc[:, :-2]\n",
    "iot_y = df_iot.iloc[:, -2:]\n",
    "\n",
    "train_and_save(iot_pipelines, 'iot', iot_x, iot_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c4ca806edb215e68744eb731c739c4121ba4017c72f37ff523d6d3cfcbd411d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
