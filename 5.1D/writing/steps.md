# steps

## Step 1: Business Understanding (Problem Definitions)

Your aim is to develop a multi-class machine learning-based classification model to identify different network traffic classes for TWO BENCHMARK DATASETS.

## Step 2: Data Gathering (Identify the source of data)

In the industry/real-world, you need to communicate either with your manager, client, other stakeholders and/or IT team to understand the source of data and to gather it.

## Step 3: Data Cleaning (Filtering anomalous data)

In a typical analysis, you may need to take care of missing values and inconsistent data. In week 2, you have learnt how to deal with missing values and manipulate a database. Here, it has already been taken care of for this dataset (so no action is needed for this task).

## Step 4: Data Exploration (Understanding the data)

Some examples of data exploration are “Identification of the attribute names (Header), Checking the length of the Train and Test dataset, Checking the total number of samples that belong to each of the five classes of the training dataset”, etc. You don’t need to do anything here. However, these actions will help you to understand the data better in practice.

## Step 5: Feature Engineering (Select Important Feature)

In a typical setup, you may need to do feature extraction or selection during your data analysis process. Here, relevant feature engineering is already done for you in the sample code. So, no action is needed for this task

## Step 6: Predictive Modelling (Prediction of the classes)

Dataset 1:
The DecisionTreeClassifier has been implemented for you. Now, you need to implement other techniques and compare. Please do the following tasks:

1. Implement at least 5 benchmark classification algorithms.
2. Tune the parameters if applicable to obtain a good solution.
3. Obtain the confusion matrix for each of the scenarios (Use the test dataset).
4. Calculate the performance measures for the each of the classification algorithms that includes Precision (%), Recall (%), F-Score (%), False Alarm- FPR (%)

Dataset 2:
A sample Random Forest implementation is given to you. Repeat the procedure as mentioned in datset 1. The only difference will be “you need to consider 70:30 train-test split (70% for train and 30% for test)” for testing as there is no separate test set file. Please note, k-fold cross validation is also acceptable. However, as k-fold cross validation will take a huge amount of time, we have not made it mandatory.

For Dataset 2, please see the article “TON_IoT Telemetry Dataset: A New Generation Dataset of IoT and IIoT for Data-Driven Intrusion Detection Systems” for Dataset 2.

## Step 7: Data Visualization

Perform the following tasks for both of the datasets:

1. Visualize and compare the accuracy of different algorithms. 2. Plot the confusion matrix for each scenarios.

## Step 8: Results delivery:

Once you have completed the data analysis task for your security project, you need to deliver the outcome. In real-world, results are typically delivered as a product/tool/web-app or through a presentation or by submitting the report. However, in our unit we will consider a report based submission only (PLEASE NOTE, the results obtained from the above steps need to be submitted as a REPORT format rather than just a screenshot).
Here, you need to write a report (at least 3500 word) based on the outcome and results you obtained by performing the above steps. The report will describe the algorithms used, their working principle, key parameters, and the results. Results should consider all the key performance measures and comparative results in the form of tables, graphs, etc.
Submit the PDF report through onTrack. You also need to submit – (i) the code file and (ii) the word/source file of the REPORT separately (within the “Code for task 5.1” folder) under the assignment tab of the CloudDeakin.

Please note, it is a graded task where you will receive some feedback and marks. Your tutor/marker will assign you some marks based on the quality of your submission, performance of your algorithms, selection and novelty in your algorithm, tuning and understanding the algorithms, how well you have explained the results, your usage of scientific language, authenticity of the claims and finally the aesthetic look of your submission and reflection of the quality of your work from the tutor’s judgement. You will receive the feedback based on the following marking rubric. The marker will judge how you have performed in the following categories.
